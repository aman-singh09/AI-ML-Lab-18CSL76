{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1734b4",
   "metadata": {},
   "source": [
    "<h2> Naive Bayes Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29540dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pima-indians-diabetes.csv'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df= pd.read_csv(filename)\n",
    "df = df.astype(float)\n",
    "\n",
    "train=df.sample(frac=0.8,random_state=105) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "# columns ['Pregnancies','Glucose','BP','SkinThickness','Insulin','BMI','DiabetesPedigree','Age','Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0628be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# group by outcomes, in the train group.\n",
    "outcome_group = train.groupby(df.columns[-1])\n",
    "n_attr = len(df.columns) -1\n",
    "summaries = {}\n",
    "#summarize by outcome, find mean and std deviation of each outcome.\n",
    "for classValue, instances in outcome_group:\n",
    "    attr_mv=[]\n",
    "    mean=list(instances.mean(axis=0).values)\n",
    "    stdev=list(instances.std(axis=0).values)\n",
    "    for i in range(n_attr):\n",
    "        attr_mv.append([mean[i],stdev[i]])\n",
    "        \n",
    "    summaries[classValue]=attr_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed6add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculateProb(x, mean, stdev):\n",
    "    exponent = math.exp(-math.pow(x-mean,2)/(2*math.pow(stdev,2)))\n",
    "    return (1 / (math.sqrt(2*math.pi)*math.pow(stdev,2))) * exponent\n",
    "  \n",
    "\n",
    "def calculateClassProb(summaries, X_vec):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = X_vec[i]\n",
    "            probabilities[classValue] *= calculateProb(x, mean, stdev)\n",
    "            \n",
    "    return probabilities\n",
    "    \n",
    "def predict(summaries, X_vec):\n",
    "    prob = calculateClassProb(summaries, X_vec)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in prob.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc34e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "predictions = []\n",
    "testSet=test.values.tolist()\n",
    "for i in range(len(testSet)):\n",
    "    result = predict(summaries, testSet[i])\n",
    "    predictions.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6c02b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 767 rows into train=614 and test=153\n",
      "Accuracy: 74.50980392156863\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(test, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        if test.iloc[i,-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "accuracy = getAccuracy(test, predictions)\n",
    "print(f'Split {len(df)} rows into train={len(train)} and test={len(test)}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b77e90",
   "metadata": {},
   "source": [
    "<h2>Using sci-kit-learn Gaussian NB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f992f724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 767 rows into train=614 and test=153\n",
      "Accuracy: 74.50980392156863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "data_train = train.iloc[:,:-1]\n",
    "target_train  = train.iloc[:,-1]\n",
    "gnb.fit(data_train, target_train)\n",
    "\n",
    "data_test = test.iloc[:,:-1]\n",
    "y_pred = gnb.predict(data_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#Model Accuracy, how often is the classifier correct?\n",
    "print(f'Split {len(df)} rows into train={len(data_train)} and test={len(data_test)}')\n",
    "print(\"Accuracy:\",(metrics.accuracy_score(test.iloc[:,-1], y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bd759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
